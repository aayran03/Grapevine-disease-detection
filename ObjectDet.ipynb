{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad65c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Create a list of all the image files in the folder\n",
    "image_files = os.listdir('/Users/aayushrangra/Desktop/ObjectDetection/cancer')\n",
    "\n",
    "# Create a TensorFlow dataset from the list of image files\n",
    "dataset = tf.data.Dataset.from_tensor_slices(image_files)\n",
    "\n",
    "# Preprocess the images in the dataset\n",
    "def preprocess_image(image):\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.subtract(image, 0.5)\n",
    "    image = tf.multiply(image, 2.0)\n",
    "    return image\n",
    "\n",
    "dataset = dataset.map(preprocess_image)\n",
    "\n",
    "# Batch the images in the dataset\n",
    "dataset = dataset.batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "968ac6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/8n/95vlvnl93lg2r18pnsrgf8f40000gn/T/__autograph_generated_fileqhrjk2g0.py\", line 10, in tf__call\n        x = ag__.converted_call(ag__.ld(self).backbone, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"yol_ov7_13\" (type YOLOv7).\n    \n    in user code:\n    \n        File \"/var/folders/8n/95vlvnl93lg2r18pnsrgf8f40000gn/T/ipykernel_2194/1593152744.py\", line 78, in call  *\n            x = self.backbone(x)\n        File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n            raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n    \n        ValueError: Input 0 of layer \"resnet50\" is incompatible with the layer: expected shape=(None, 416, 416, 3), found shape=(None, 224, 224, None)\n    \n    \n    Call arguments received by layer \"yol_ov7_13\" (type YOLOv7):\n      • x=tf.Tensor(shape=(None, 224, 224, None), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 100\u001b[0m\n\u001b[1;32m     95\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     96\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     97\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/8n/95vlvnl93lg2r18pnsrgf8f40000gn/T/__autograph_generated_filebfo4t1fv.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/8n/95vlvnl93lg2r18pnsrgf8f40000gn/T/__autograph_generated_fileqhrjk2g0.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mbackbone, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mneck, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mhead, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/8n/95vlvnl93lg2r18pnsrgf8f40000gn/T/__autograph_generated_fileqhrjk2g0.py\", line 10, in tf__call\n        x = ag__.converted_call(ag__.ld(self).backbone, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"yol_ov7_13\" (type YOLOv7).\n    \n    in user code:\n    \n        File \"/var/folders/8n/95vlvnl93lg2r18pnsrgf8f40000gn/T/ipykernel_2194/1593152744.py\", line 78, in call  *\n            x = self.backbone(x)\n        File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n            raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n    \n        ValueError: Input 0 of layer \"resnet50\" is incompatible with the layer: expected shape=(None, 416, 416, 3), found shape=(None, 224, 224, None)\n    \n    \n    Call arguments received by layer \"yol_ov7_13\" (type YOLOv7):\n      • x=tf.Tensor(shape=(None, 224, 224, None), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class YOLOv7(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(YOLOv7, self).__init__()\n",
    "\n",
    "        # Backbone network\n",
    "        self.backbone = tf.keras.applications.ResNet50(\n",
    "            input_shape=(416, 416, 3),\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "\n",
    "        # Neck network\n",
    "        self.neck = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        ])\n",
    "\n",
    "        # Head network\n",
    "        self.head = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(num_classes * 85, (1, 1), activation='linear'),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone features\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        # Neck features\n",
    "        x = self.neck(x)\n",
    "\n",
    "        # Head features\n",
    "        x = self.head(x)\n",
    "\n",
    "        # Reshape the output to (B, H, W, 85 * C)\n",
    "        x = tf.reshape(x, (-1, x.shape[1], x.shape[2], 85 * num_classes))\n",
    "\n",
    "        return x\n",
    "\n",
    "# Create a YOLOv7 model\n",
    "model = YOLOv7(num_classes=80)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class YOLOv7(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(YOLOv7, self).__init__()\n",
    "\n",
    "        # Backbone network\n",
    "        self.backbone = tf.keras.applications.ResNet50(\n",
    "            input_shape=(416, 416, 3),\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "\n",
    "        # Neck network\n",
    "        self.neck = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        ])\n",
    "\n",
    "        # Head network\n",
    "        self.head = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(num_classes * 85, (1, 1), activation='linear'),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        # Backbone features\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        # Neck features\n",
    "        x = self.neck(x)\n",
    "\n",
    "        # Head features\n",
    "        x = self.head(x)\n",
    "\n",
    "        # Reshape the output to (B, H, W, 85 * C)\n",
    "        x = tf.reshape(x, (-1, x.shape[1], x.shape[2], 85 * num_classes))\n",
    "\n",
    "        return x\n",
    "    \n",
    "# Create a YOLOv7 model\n",
    "model = YOLOv7(num_classes=80)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80dad8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Layer, GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Activation, Multiply, Add\n",
    "\n",
    "class RCBAM(Layer):\n",
    "    def __init__(self, channels):\n",
    "        super(RCBAM, self).__init__()\n",
    "\n",
    "        # Channel Attention Module (CAM)\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.max_pool = Conv2D(channels // 16, (1, 1), padding='same')\n",
    "        self.channel_attention = Dense(channels, activation='sigmoid')\n",
    "\n",
    "        # Spatial Attention Module (SAM)\n",
    "        self.conv1 = Conv2D(channels // 16, (1, 1), padding='same')\n",
    "        self.conv2 = Conv2D(channels // 16, (7, 7), padding='same')\n",
    "        self.spatial_attention = Dense(channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Channel Attention Module (CAM)\n",
    "        avg_pool = self.avg_pool(inputs)\n",
    "        max_pool = self.max_pool(inputs)\n",
    "        channel_attention = self.channel_attention(avg_pool + max_pool)\n",
    "\n",
    "        # Spatial Attention Module (SAM)\n",
    "        avg_branch = self.conv1(inputs)\n",
    "        max_branch = self.conv2(inputs)\n",
    "        spatial_attention = self.spatial_attention(tf.concat([avg_branch, max_branch], axis=-1))\n",
    "\n",
    "        # RCBAM\n",
    "        channel_attention = tf.expand_dims(channel_attention, axis=1)\n",
    "        spatial_attention = tf.expand_dims(spatial_attention, axis=-1)\n",
    "        attention = Multiply()([channel_attention, spatial_attention])\n",
    "        output = Multiply()([inputs, attention])\n",
    "        output = Add()([inputs, output])\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c725aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAM(tf.keras.Model):\n",
    "    def __init__(self, channels):\n",
    "        super(PAM, self).__init__()\n",
    "\n",
    "        self.channel_attention = tf.keras.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(channels // 16, activation='relu'),\n",
    "            tf.keras.layers.Dense(channels, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        self.spatial_attention = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters=1, kernel_size=(7, 7), padding='same', activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=channels, kernel_size=(7, 7), padding='same', activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        channel_attention = self.channel_attention(inputs)\n",
    "        spatial_attention = self.spatial_attention(inputs)\n",
    "\n",
    "        attention = channel_attention * spatial_attention\n",
    "\n",
    "        # Broadcast the attention tensor to the same shape as the inputs tensor\n",
    "        attention = tf.broadcast_to(attention, tf.shape(inputs))\n",
    "\n",
    "        return inputs * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2761ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 05:38:09.058550: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create the SSD model\n",
    "resnet = tf.keras.applications.resnet50.ResNet50(\n",
    "    input_shape=(224, 224, 3), \n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(224, 224, 3)))\n",
    "model.add(resnet)\n",
    "# Add the RCBAM attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8dad387",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2869\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2847\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   2848\u001b[0m \n\u001b[1;32m   2849\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2866\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   2867\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m-> 2869\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2870\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2871\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2872\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2873\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[1;32m   2874\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2875\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2878\u001b[0m     expand_nested\u001b[38;5;241m=\u001b[39mexpand_nested,\n\u001b[1;32m   2879\u001b[0m     show_trainable\u001b[38;5;241m=\u001b[39mshow_trainable)\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6b4b397",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Received: layer=<class '__main__.RCBAM'> of type <class 'type'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRCBAM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Add the following line:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m2048\u001b[39m))))\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/sequential.py:178\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    176\u001b[0m     layer \u001b[38;5;241m=\u001b[39m functional\u001b[38;5;241m.\u001b[39mModuleWrapper(layer)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe added layer must be an instance of class Layer. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    179\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived: layer=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    181\u001b[0m tf_utils\u001b[38;5;241m.\u001b[39massert_no_legacy_layers([layer])\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n",
      "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Received: layer=<class '__main__.RCBAM'> of type <class 'type'>."
     ]
    }
   ],
   "source": [
    "model.add(RCBAM)\n",
    "\n",
    "# Add the following line:\n",
    "model.add(tf.keras.layers.Lambda(lambda x: tf.reshape(x, (-1, 7, 7, 2048))))\n",
    "model.add(PAM(channels=2048))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add a dilated convolution layer to the end of the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), dilation_rate=2, activation='relu', input_shape=(64, 64, 3)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d5ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 60, 60, 64)        1792      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3c6a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add a flatten layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "\n",
    "\n",
    "# Add a dense layer with 2 output units\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2198c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='conv2d_4_input'), name='conv2d_4_input', description=\"created by layer 'conv2d_4_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_5\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_4\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"sequential_5\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrain_tumor_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/8n/95vlvnl93lg2r18pnsrgf8f40000gn/T/__autograph_generated_filebmhqwbc1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_5\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_4\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"sequential_5\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=10)\n",
    "\n",
    "# Save the model\n",
    "model.save('brain_tumor_model.h5')\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('brain_tumor_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the input image\n",
    "img = tf.io.decode_jpeg(tf.io.read_file('brain_tumor_image.jpg'))\n",
    "\n",
    "# Preprocess the image\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "img = tf.subtract(img, 0.5)\n",
    "img = tf.multiply(img, 2.0)\n",
    "\n",
    "# Detect objects in the image\n",
    "detections = model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5083c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the detections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "\n",
    "for detection in detections:\n",
    "    bbox = detection['bbox'].decode('utf-8')\n",
    "    ax.add_patch(tf.keras.preprocessing.image.Rectangle(\n",
    "    bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1], color='red'\n",
    "))\n",
    "\n",
    "ax.set_title('Brain tumor detection using SSD with ResNet-50 backbone, RCBAM, PAM and dilated convolution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3604e872",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nvidia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnvidia\u001b[49m\u001b[38;5;241m-\u001b[39msmi\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nvidia' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0989d2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 625ms/step\n",
      "Class: espa\n",
      "\n",
      "Confidence Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"keras_Model.h5\", compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"labels.txt\", \"r\").readlines()\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image = Image.open(\"/Users/aayushrangra/Desktop/ObjectDetection/LeafDisease/Grape Esca Black Measles/Grape_Esca_Black_Measles8465.jpg\").convert(\"RGB\")\n",
    "\n",
    "# resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "\n",
    "# turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# Predicts the model\n",
    "prediction = model.predict(data)\n",
    "index = np.argmax(prediction)\n",
    "class_name = class_names[index]\n",
    "confidence_score = prediction[0][index]\n",
    "\n",
    "# Print prediction and confidence score\n",
    "print(\"Class:\", class_name[2:])\n",
    "print(\"Confidence Score:\", confidence_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed3e0ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._custom_ops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEfficientNetMG\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.cache/torch/hub/pyTorch_vision_main/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/torch/hub/pyTorch_vision_main/torchvision/_meta_registrations.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_ops\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure that torch.ops.torchvision is visible\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._custom_ops'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "class EfficientNetMG(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(EfficientNetMG, self).__init__()\n",
    "\n",
    "        # Load the EfficientNet-MG pre-trained weights from ImageNet\n",
    "        efficientnet = models.efficientnet_mg(pretrained=True)\n",
    "\n",
    "\n",
    "        # Remove the last classification layer\n",
    "        efficientnet.classifier = nn.Identity()\n",
    "\n",
    "        # Add a new multi-scale feature fusion (MSFF) module\n",
    "        self.msff = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2048, out_channels=1280, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(in_channels=1280, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Add the final classification layer\n",
    "        self.classifier = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input image through the EfficientNet-MG model\n",
    "        x = efficientnet(x)\n",
    "\n",
    "        # Pass the output features through the MSFF module\n",
    "        x = self.msff(x)\n",
    "\n",
    "        # Flatten the features and pass them through the final classification layer\n",
    "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "model = EfficientNetMG(pretrained=True)\n",
    "\n",
    "# Load the image\n",
    "image = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Pass the image through the model\n",
    "output = model(image)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = torch.argmax(output, dim=1)\n",
    "\n",
    "# Print the predicted class\n",
    "print(predicted_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec79646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2  # or from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9092e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of directories with images\n",
    "directories = ['Grape Black rot', 'Grape Esca Black Measles', 'Grape healthy', 'Grape Leaf blight Isariopsis Leaf Spot']\n",
    "\n",
    "# Preprocessing steps\n",
    "def preprocess_image(image):\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image / 255.0\n",
    "    image -= [0.485, 0.456, 0.406]\n",
    "    image /= [0.229, 0.224, 0.225]\n",
    "    return image\n",
    "\n",
    "# Loop through each directory\n",
    "for directory in directories:\n",
    "    directory_path = os.path.join('/Users/aayushrangra/Desktop/GrapeVine_Disease_Detection/LeafDisease', directory)\n",
    "    \n",
    "    # Create a new directory for preprocessed images\n",
    "    output_directory = os.path.join('preprocessed_images', directory)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # List image files in the current directory\n",
    "    image_files = [f for f in os.listdir(directory_path) if f.endswith(('.jpg', '.png', '.jpeg', '.gif'))]\n",
    "\n",
    "    # Process and save images\n",
    "    for filename in image_files:\n",
    "        image_path = os.path.join(directory_path, filename)\n",
    "        image = cv2.imread(image_path)  # or Image.open(image_path) if using PIL\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        output_path = os.path.join(output_directory, 'preprocessed_' + filename)\n",
    "        cv2.imwrite(output_path, preprocessed_image)  # or preprocessed_image.save(output_path) if using PIL\n",
    "        if image is not None:\n",
    "            preprocessed_image = preprocess_image(image)\n",
    "            \n",
    "            output_path = os.path.join(output_directory, 'preprocessed_' + filename)\n",
    "            cv2.imwrite(output_path, (preprocessed_image * 255).astype('uint8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab35b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
