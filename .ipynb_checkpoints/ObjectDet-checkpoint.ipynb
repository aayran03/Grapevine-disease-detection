{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "968ac6d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible shape for value ((480, 640, 3)), expected ((480, 720, 3))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     11\u001b[0m image_files \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(image_files)\n\u001b[0;32m---> 13\u001b[0m image_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m image_tensors \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(image_tensors, (\u001b[38;5;241m480\u001b[39m, \u001b[38;5;241m720\u001b[39m))\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    623\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    624\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    625\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[38;5;241m.\u001b[39mget_qualified_name(func),\n\u001b[1;32m    627\u001b[0m             func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, arg_name, arg_value, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    628\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date), instructions)\n\u001b[0;32m--> 629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    554\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    555\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    556\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    559\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    560\u001b[0m           instructions)\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/map_fn.py:637\u001b[0m, in \u001b[0;36mmap_fn_v2\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn_output_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m   fn_output_signature \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43melems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melems\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_output_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_output_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mback_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mback_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    554\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    555\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    556\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    559\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    560\u001b[0m           instructions)\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/map_fn.py:495\u001b[0m, in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    490\u001b[0m   tas \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    491\u001b[0m       ta\u001b[38;5;241m.\u001b[39mwrite(i, value) \u001b[38;5;28;01mfor\u001b[39;00m (ta, value) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tas, result_value_batchable)\n\u001b[1;32m    492\u001b[0m   ]\n\u001b[1;32m    493\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, tas)\n\u001b[0;32m--> 495\u001b[0m _, r_a \u001b[38;5;241m=\u001b[39m \u001b[43mcontrol_flow_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_batchable_ta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mback_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mback_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m result_batchable \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mstack() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m r_a]\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# Update each output tensor w/ static shape info about the outer dimension.\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py:2754\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m loop_var_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(type_spec\u001b[38;5;241m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m   2752\u001b[0m                                         \u001b[38;5;28mlist\u001b[39m(loop_vars))\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cond(\u001b[38;5;241m*\u001b[39mloop_vars):\n\u001b[0;32m-> 2754\u001b[0m   loop_vars \u001b[38;5;241m=\u001b[39m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2755\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m try_to_pack \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loop_vars, (\u001b[38;5;28mlist\u001b[39m, _basetuple)):\n\u001b[1;32m   2756\u001b[0m     packed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py:2745\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2742\u001b[0m     loop_vars \u001b[38;5;241m=\u001b[39m (counter, loop_vars)\n\u001b[1;32m   2743\u001b[0m     cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m i, lv: (  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m   2744\u001b[0m         math_ops\u001b[38;5;241m.\u001b[39mlogical_and(i \u001b[38;5;241m<\u001b[39m maximum_iterations, orig_cond(\u001b[38;5;241m*\u001b[39mlv)))\n\u001b[0;32m-> 2745\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m i, lv: (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[43morig_body\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2746\u001b[0m   try_to_pack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executing_eagerly:\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/map_fn.py:490\u001b[0m, in \u001b[0;36mmap_fn.<locals>.compute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    487\u001b[0m result_value_flat \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(result_value)\n\u001b[1;32m    488\u001b[0m result_value_batchable \u001b[38;5;241m=\u001b[39m _result_value_flat_to_batchable(\n\u001b[1;32m    489\u001b[0m     result_value_flat, result_flat_signature)\n\u001b[0;32m--> 490\u001b[0m tas \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    491\u001b[0m     ta\u001b[38;5;241m.\u001b[39mwrite(i, value) \u001b[38;5;28;01mfor\u001b[39;00m (ta, value) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tas, result_value_batchable)\n\u001b[1;32m    492\u001b[0m ]\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, tas)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/map_fn.py:491\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    487\u001b[0m result_value_flat \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(result_value)\n\u001b[1;32m    488\u001b[0m result_value_batchable \u001b[38;5;241m=\u001b[39m _result_value_flat_to_batchable(\n\u001b[1;32m    489\u001b[0m     result_value_flat, result_flat_signature)\n\u001b[1;32m    490\u001b[0m tas \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 491\u001b[0m     \u001b[43mta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (ta, value) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tas, result_value_batchable)\n\u001b[1;32m    492\u001b[0m ]\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, tas)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/tf_should_use.py:243\u001b[0m, in \u001b[0;36mshould_use_result.<locals>.decorated.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 243\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _add_should_use_warning(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    244\u001b[0m                                  warn_in_eager\u001b[38;5;241m=\u001b[39mwarn_in_eager,\n\u001b[1;32m    245\u001b[0m                                  error_in_function\u001b[38;5;241m=\u001b[39merror_in_function)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/tensor_array_ops.py:1166\u001b[0m, in \u001b[0;36mTensorArray.write\u001b[0;34m(self, index, value, name)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;129m@tf_should_use\u001b[39m\u001b[38;5;241m.\u001b[39mshould_use_result(warn_in_eager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, index, value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Write `value` into index `index` of the TensorArray.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;124;03m    ValueError: if there are more writers than specified.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1166\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_implementation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/tensor_array_ops.py:843\u001b[0m, in \u001b[0;36m_EagerTensorArray.write\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See TensorArray.\"\"\"\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m name  \u001b[38;5;66;03m# not meaningful when executing eagerly.\u001b[39;00m\n\u001b[0;32m--> 843\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent()\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/tensor_array_ops.py:832\u001b[0m, in \u001b[0;36m_EagerTensorArray._write\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mInvalidArgumentError(\n\u001b[1;32m    827\u001b[0m       \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    828\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorArray dtype is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but Op is trying to write dtype \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    829\u001b[0m       (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype\u001b[38;5;241m.\u001b[39mname, value\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape\u001b[38;5;241m.\u001b[39mis_compatible_with(value\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 832\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shape for value (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m), expected (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    833\u001b[0m                    (value\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape))\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_shape:\n\u001b[1;32m    836\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape\u001b[38;5;241m.\u001b[39mmerge_with(value\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shape for value ((480, 640, 3)), expected ((480, 720, 3))"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get a list of the image files\n",
    "image_files = tf.io.gfile.glob('cars_train/*.jpg')\n",
    "\n",
    "# Create a dataset from the list of image files\n",
    "dataset = tf.data.Dataset.from_tensor_slices(image_files)\n",
    "\n",
    "# Batch the images\n",
    "dataset = dataset.batch(32)\n",
    "image_files = tf.constant(image_files)\n",
    "\n",
    "image_tensors = tf.map_fn(\n",
    "    lambda image_files: tf.cast(tf.image.decode_image(tf.io.read_file(image_files)), tf.float32),\n",
    "    image_files,\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "image_tensors = tf.image.resize(image_tensors, (480, 720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80dad8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCBAM(tf.keras.Model):\n",
    "    def __init__(self, channels):\n",
    "        super(RCBAM, self).__init__()\n",
    "\n",
    "        self.channel_attention = tf.keras.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(channels // 16, activation='relu'),\n",
    "            tf.keras.layers.Dense(channels, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        self.spatial_attention = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters=1, kernel_size=(7, 7), padding='same', activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=channels, kernel_size=(7, 7), padding='same', activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        channel_attention = self.channel_attention(inputs)\n",
    "        spatial_attention = self.spatial_attention(inputs)\n",
    "\n",
    "        # Reshape channel_attention to have the same number of channels as the input\n",
    "        channel_attention = tf.reshape(channel_attention, (-1, 1, 1, tf.shape(inputs)[-1]))\n",
    "        # Tile channel_attention to match the spatial_attention dimensions\n",
    "        channel_attention = tf.tile(channel_attention, [1, tf.shape(inputs)[1], tf.shape(inputs)[2], 1])\n",
    "\n",
    "        attention = channel_attention * spatial_attention\n",
    "\n",
    "        # Apply attention to the input tensor\n",
    "        attended_inputs = inputs * attention\n",
    "\n",
    "        return attended_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c725aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAM(tf.keras.Model):\n",
    "    def __init__(self, channels):\n",
    "        super(PAM, self).__init__()\n",
    "\n",
    "        self.channel_attention = tf.keras.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(channels // 16, activation='relu'),\n",
    "            tf.keras.layers.Dense(channels, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        self.spatial_attention = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters=1, kernel_size=(7, 7), padding='same', activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=channels, kernel_size=(7, 7), padding='same', activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        channel_attention = self.channel_attention(inputs)\n",
    "        spatial_attention = self.spatial_attention(inputs)\n",
    "\n",
    "        attention = channel_attention * spatial_attention\n",
    "\n",
    "        # Broadcast the attention tensor to the same shape as the inputs tensor\n",
    "        attention = tf.broadcast_to(attention, tf.shape(inputs))\n",
    "\n",
    "        return inputs * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2761ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SSD model\n",
    "resnet = tf.keras.applications.resnet50.ResNet50(\n",
    "    input_shape=(224, 224, 3), \n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(224, 224, 3)))\n",
    "model.add(resnet)\n",
    "# Add the RCBAM attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8dad387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b4b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(RCBAM(channels=2048))\n",
    "\n",
    "# Add the following line:\n",
    "model.add(tf.keras.layers.Lambda(lambda x: tf.reshape(x, (-1, 7, 7, 2048))))\n",
    "model.add(PAM(channels=2048))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add a dilated convolution layer to the end of the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), dilation_rate=2, activation='relu', input_shape=(64, 64, 3)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d5ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 60, 60, 64)        1792      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3c6a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add a flatten layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "\n",
    "\n",
    "# Add a dense layer with 2 output units\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2198c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='conv2d_4_input'), name='conv2d_4_input', description=\"created by layer 'conv2d_4_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_5\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_4\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"sequential_5\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrain_tumor_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/8n/95vlvnl93lg2r18pnsrgf8f40000gn/T/__autograph_generated_filebmhqwbc1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_5\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_4\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"sequential_5\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=10)\n",
    "\n",
    "# Save the model\n",
    "model.save('brain_tumor_model.h5')\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('brain_tumor_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the input image\n",
    "img = tf.io.decode_jpeg(tf.io.read_file('brain_tumor_image.jpg'))\n",
    "\n",
    "# Preprocess the image\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "img = tf.subtract(img, 0.5)\n",
    "img = tf.multiply(img, 2.0)\n",
    "\n",
    "# Detect objects in the image\n",
    "detections = model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5083c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the detections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "\n",
    "for detection in detections:\n",
    "    bbox = detection['bbox'].decode('utf-8')\n",
    "    ax.add_patch(tf.keras.preprocessing.image.Rectangle(\n",
    "    bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1], color='red'\n",
    "))\n",
    "\n",
    "ax.set_title('Brain tumor detection using SSD with ResNet-50 backbone, RCBAM, PAM and dilated convolution')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
