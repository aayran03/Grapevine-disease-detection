{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f174f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_json, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71d8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 =image.load_img('/Users/aayushrangra/Desktop/GrapeVine_Disease_Detection/GrapevineLeafDataset/train/Ak/Ak (67).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588db869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir ='/Users/aayushrangra/Desktop/GrapeVine_Disease_Detection/GrapevineLeafDataset/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c3b01eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 511, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread('/Users/aayushrangra/Desktop/GrapeVine_Disease_Detection/GrapevineLeafDataset/train/Ak/Ak (67).png').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc21362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4102c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, BatchNormalization\n",
    "from keras.applications import VGG16\n",
    "#from keras.preprocessing import image\n",
    "\n",
    "IMAGE_SIZE = [511, 511]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "\n",
    "# loading the weights of VGG16 without the top layer. These weights are trained on Imagenet dataset.\n",
    "vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  # input_shape = (64,64,3) as required by VGG\n",
    "\n",
    "# this will exclude the initial layers from training phase as there are already been trained.\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)                        # we can add a new fully connected layer but it will increase the execution time.\n",
    "x = Dense(num_classes, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b01f225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir ='/Users/aayushrangra/Desktop/GrapeVine_Disease_Detection/GrapevineLeafDataset/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f493df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5379 images belonging to 5 classes.\n",
      "Found 568 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = [511, 511]\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "    )\n",
    "val_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "    )  \n",
    "\n",
    "\n",
    "train_set = train_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = 16\n",
    "    )\n",
    "val_set = val_gen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = 16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f88e60db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 511, 511, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 511, 511, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 511, 511, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 255, 255, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 255, 255, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 255, 255, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 127, 127, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 127, 127, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 127, 127, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 127, 127, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 63, 63, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 63, 63, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 63, 63, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 63, 63, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 31, 31, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 15, 15, 512)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 115200)            0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 115200)           460800    \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               14745728  \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,922,373\n",
      "Trainable params: 14,977,029\n",
      "Non-trainable params: 14,945,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c203b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/337 [>.............................] - ETA: 3:07:51 - loss: 3.4768 - accuracy: 0.2344"
     ]
    }
   ],
   "source": [
    "VGG_model = model.fit(\n",
    "     train_set,\n",
    "     validation_data=val_set, \n",
    "     epochs=1,\n",
    "     steps_per_epoch = len(train_set),\n",
    "     validation_steps = len(val_set),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9bf94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('VGG16_grapeleavestypes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68513ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/Users/aayushrangra/Desktop/GrapeVine_Disease_Detection/GrapevineLeafDataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb03791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0474b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = inception_model.history['accuracy']\n",
    "val_acc = inception_model.history['val_accuracy']\n",
    "\n",
    "loss = inception_model.history['loss']\n",
    "val_loss = inception_model.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1), acc, label='Training Accuracy')\n",
    "plt.plot(range(1), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1), loss, label='Training Loss')\n",
    "plt.plot(range(1), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9093d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac7db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96df78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dffe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_set, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming acc_train, acc_test, and acc_val are lists with accuracy values\n",
    "# Replace these with your actual values\n",
    "\n",
    "acc_train = [0.9576]  # Replace with your actual value for training accuracy\n",
    "acc_test = [0.9759]   # Replace with your actual value for test accuracy\n",
    "acc_val = [0.9816]    # Replace with your actual value for validation accuracy\n",
    "\n",
    "# Set up the figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Define colors for each bar\n",
    "colors = ['blue', 'orange', 'green']\n",
    "\n",
    "# Bar graph for accuracy\n",
    "bar_width = 0.3\n",
    "bar_positions = np.arange(3)\n",
    "\n",
    "ax.bar(bar_positions, [acc_train[0], acc_test[0], acc_val[0]], width=bar_width, alpha=0.5, color=colors, label='Accuracy')\n",
    "\n",
    "# Set labels and ticks\n",
    "ax.set_xticks(bar_positions)\n",
    "ax.set_xticklabels(['Training', 'Test', 'Validation'])\n",
    "\n",
    "\n",
    "plt.title('Training, Test, and Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc343b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
