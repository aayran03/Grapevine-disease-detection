{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc02ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e04bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <CC4BC91F-8B6A-3F9A-B9EB-A2B9D578E202> /Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <FB753559-B5BA-3279-8C4E-2AB6619F0AE9> /Applications/anaconda3/lib/python3.9/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T # for simplifying the transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24636e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1842c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fbbc874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a9ef5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e1cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(data_dir):\n",
    "    all_data = datasets.ImageFolder(data_dir)\n",
    "    return all_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db43f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(data_dir, batch_size, train = False):\n",
    "    if train:\n",
    "        #train\n",
    "        transform = T.Compose([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "            T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.25),\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD), # imagenet means\n",
    "            T.RandomErasing(p=0.1, value='random')\n",
    "        ])\n",
    "        train_data = datasets.ImageFolder(os.path.join(data_dir, \"train/\"), transform = transform)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        return train_loader, len(train_data)\n",
    "    else:\n",
    "        # val/test\n",
    "        transform = T.Compose([ # We dont need augmentation for test transforms\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD), # imagenet means\n",
    "        ])\n",
    "        val_data = datasets.ImageFolder(os.path.join(data_dir, \"validation/\"), transform=transform)\n",
    "        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        return val_loader, test_loader, len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5313e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/aayushrangra/Desktop/GrapeVine_Disease_Detection/custom_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0992b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_loader, train_data_len) = get_data_loaders(dataset_path, 128, train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c27e340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grape Black rot', 'Grape Esca Black Measles', 'Grape Leaf blight Isariopsis Leaf Spot', 'Grape healthy'] 4\n"
     ]
    }
   ],
   "source": [
    "classes = get_classes(\"/Users/aayushrangra/Desktop/GrapeVine_Disease_Detection/custom_dataset/train/\")\n",
    "print(classes, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0288b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loaders(dataset_path, 32, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ace60c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": val_loader\n",
    "}\n",
    "dataset_sizes = {\n",
    "    \"train\": train_data_len,\n",
    "    \"val\": valid_data_len\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d4bcdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 90 225\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c41f6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25895 2875 7190\n"
     ]
    }
   ],
   "source": [
    "print(train_data_len, valid_data_len, test_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcd847c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4066e4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/SharanSMenon/swin-transformer-hub/zipball/main\" to /Users/aayushrangra/.cache/torch/hub/main.zip\n",
      "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth\" to /Users/aayushrangra/.cache/torch/hub/checkpoints/swin_tiny_patch4_window7_224.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556f896e40a3458d84d98600d0e83d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\n",
    "MODEL_NAME = \"swin_tiny_patch4_window7_224\"\n",
    "# check hubconf for more models.\n",
    "model = torch.hub.load(HUB_URL, MODEL_NAME, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5f4ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters(): #freeze model\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_inputs = model.head.in_features\n",
    "model.head = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, len(classes))\n",
    ")\n",
    "model = model.to(device)\n",
    "print(model.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed490828",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = LabelSmoothingCrossEntropy()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.AdamW(model.head.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f55c3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a79df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print(\"-\"*10)\n",
    "        \n",
    "        for phase in ['train', 'val']: # We do training and validation phase per epoch\n",
    "            if phase == 'train':\n",
    "                model.train() # model to training mode\n",
    "            else:\n",
    "                model.eval() # model to evaluate\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1) # used for accuracy\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step() # step at end of epoch\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n",
    "        print()\n",
    "    time_elapsed = time.time() - since # slight error\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac64a5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/203 [00:00<?, ?it/s]/Applications/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <CC4BC91F-8B6A-3F9A-B9EB-A2B9D578E202> /Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <FB753559-B5BA-3279-8C4E-2AB6619F0AE9> /Applications/anaconda3/lib/python3.9/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <CC4BC91F-8B6A-3F9A-B9EB-A2B9D578E202> /Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <FB753559-B5BA-3279-8C4E-2AB6619F0AE9> /Applications/anaconda3/lib/python3.9/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <CC4BC91F-8B6A-3F9A-B9EB-A2B9D578E202> /Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <FB753559-B5BA-3279-8C4E-2AB6619F0AE9> /Applications/anaconda3/lib/python3.9/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <CC4BC91F-8B6A-3F9A-B9EB-A2B9D578E202> /Applications/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <FB753559-B5BA-3279-8C4E-2AB6619F0AE9> /Applications/anaconda3/lib/python3.9/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      " 11%|████▎                                   | 22/203 [15:03<2:09:39, 42.98s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa940ecea60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1474, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Applications/anaconda3/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Applications/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Applications/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Applications/anaconda3/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      " 11%|████▎                                   | 22/203 [15:40<2:08:53, 42.73s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dbfb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0 for i in range(len(classes)))\n",
    "class_total = list(0 for i in range(len(classes)))\n",
    "model_ft.eval()\n",
    "\n",
    "for data, target in tqdm(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    with torch.no_grad(): # turn off autograd for faster testing\n",
    "        output = model_ft(data)\n",
    "        loss = criterion(output, target)\n",
    "    test_loss = loss.item() * data.size(0)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    if len(target) == 32:\n",
    "        for i in range(32):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "test_loss = test_loss / test_data_len\n",
    "print('Test Loss: {:.4f}'.format(test_loss))\n",
    "for i in range(len(classes)):\n",
    "    if class_total[i] > 0:\n",
    "        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n",
    "            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Test accuracy of %5s: NA\" % (classes[i]))\n",
    "print(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n",
    "            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.rand(1, 3, 224, 224)\n",
    "traced_script_module = torch.jit.trace(model.cpu(), example)\n",
    "traced_script_module.save(\"butterfly_swin_transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333e2177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
